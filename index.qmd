---
title: "RDA Researcher Guide"
author: The Optical Radiation Exposure and Visual Experience Data Working Group
bibliography: references.bib
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 3
    toc-expand: 2
---

This site will shortly host the Research Data Alliance (RDA) Research Guide. The Research Guide is authored by the [Optical Radiation Exposure and Visual Experience Data Working Group](https://www.rd-alliance.org/groups/optical-radiation-exposure-and-visual-experience-data-wg/activity/). The site is built using [Quarto](https://quarto.org/docs/websites), a scientific and technical publishing system.

# Introduction

Exposure to the optical environment, sometimes called visual experience, fundamentally affects human physiology and behaviour at multiple time scales. Two examples of such effects that have received significant attention come from different research domains, but can be understood through a common retinally-referenced framework. The first concerns the 'non-visual' effect of light on human circadian and neuroendocrine physiology: The light-dark cycle synchronises the biological clock, and exposure to light at night suppresses melatonin production. The second concerns the potential effect of light exposure and visual experience on ocular development and specific myopia, in which time spent outdoors, and its associated visual experience, have been linked with ocular health outcomes.

In typical laboratory studies, light exposure can be fixed and held constant, or modulated parametrically. Such artificial exposures are very much unlike the real-world exposures to the optical environment that people received through the day. As people move in and between spaces (indoors and outdoors) and move their trunks, heads and eyes, the exposure to the optical environment varies significantly, and is modulated by behaviour. As a consequence, understanding real-world exposure to link to real-world impacts requires real-world measurements, faciliated by wearable devices.

Starting in the 1980s, technology to measure exposure to the optical environment has been developed and matured, with miniaturized illuminance sensors now (2025) being very common in consumer smartwatches. In research, several device and device types are available, which differ in their functionality. To make informed decisions about the properties of specific devices requires a careful ascertainment of their properties, and the specific trade-offs they entail.

# Scope

The scope of this Researcher Guide is to provide a guide to the use of wearable devices measuring the optical environment. It is a living document, and can be updated.

# Researcher Guide

## Selecting Devices

### Measurement capabilities and sensor characteristics
Spectral/photometric/α-opic metrics, sampling rate, uncertainty, cosine response, range, etc. [@Spitschan2022DigitHealth]

 [@vanDuijnhoven2025BuildEnviron]

### Advanced and additional modalities
Spatial resolution, movement tracking, UV/IR detection.

### Manufacturer calibration

Devices designed to measure light exposure and other aspects of the optical environment should come with information from the manufacturer on the calibration procedures used to ensure high-quality measurements. Sometimes, information for one exemplary device is included in a spec sheet or datasheet. It is worth consulting with the manufacturer on any calibrations they perform, and specifically clarify whether device-level information is available.

The manufacturer may also recommend recalibrations of the devices at regular intervals. It is worth understanding the rationale for any such recalibrations (in particular if they come at a cost), and also any recalibrations that can be done by researchers themselves.

### Size, form, and design

The size, form and design of a wearable light logger is particular important for the specific contexts in which it will be used. Devices that are too heavy, bulky or impractically shaped will likely not be of particular use in field studies on light exposure. The most common form factors are devices that are **wrist-worn**, **lanyard-worn**, attached with a **clip**, or attached to **spectacle frames**.

Different form factors are susceptible to different types of occlusions, so beyond participant comfort, a device's dimensions and intended use case are also directly linked to data reliability. As of 2025, no specific device can be used all the time in all contexts and provide reliable information.

Common problems include:

– Wrist-worn devices are susceptible to being occluded by sleeves, particularly in settings or cold weather seasons.

- Lanyard-worn and clip-worn devices are susceptible to being occluded by jackets or other outer garments.

- Devices attached to spectacle frames are impractical for long-term use in the real world.

### Battery capacity
Battery life, charging cycles, power management.

### Data storage
Storage capacity, retention, and privacy.

### Raw data format and ease of use
Export formats, transfer speed, and syntactic structure.

### Wear/non-wear and occlusion detection

Some devices may be able to detect whether they are being worn, either online, or after analysis using the manufacturer-provided software. For wrist-worn devices, this could be implemented through a capacitance sensor, or temperature sensor, or in conjunction with data from the IMU. Additionally, devices might be able to detect it is occluded.

When wear detection is not available from the device-inherent capabilities, it is recommended that researchers investigate concise methods for estimating wear/non-wear state, e.g. through additional questionnaires or using a data-driven approach.

### Interaction with the device

Some devices contain event buttons, which, when pressed, insert time-stamped information into the data log. This functionality can be very useful for determining wear/non-wear state and specific events taking place for the participant. It is worth noting that as they are a user interaction, it is not guaranteed that participants will do it consistently.

### Documentation
Quality of manufacturer documentation.

### Software ecosystem
Features for annotation, tagging, and version control. [@Zauner2025JOpenSourceSoftw]

## Validating Devices

### Standardized validation procedures
General principles and methodology.

### Cross-comparison with reference measurements
Using standard light sources.

### Inter-device variability assessment
Comparing devices.

### Intra-device reliability assessment
Same-device repeatability.

### Ease of calibration
Individual recalibration support.

## Designing the Study

### Clarity on research question

Research questions, hypotheses, procedures and methods need to be aligned. In the context of measuring visual experience and light exposure, measuring one day of light exposure to understand seasonal effects is inappropriate.

### Participant burden vs. fidelity
Balancing precision with practicality.

### Measurement capabilities matched to use case
Light level dependence.

### Measurement length and time intervals
Sampling strategy and battery considerations.

### Inclusion of other data
Sleep, activity, and context. [@Guidolin2045BMCPublicHealth]

### Behavioral modification through wearing location
How wear location may affect behavior.

## Collecting Data

### Briefing of participants
Instructions and precautions.

### Recurrent compliance checks
Monitoring adherence.

### Device settings
Logging configuration, time sync, DST handling.

## Storing and Documenting Data

### Consistent file format
Non-proprietary standard formats.

### Auxiliary data
Surveys, companion apps.

### Standard directory structure
File organization.

### Documentation of anomalies
Participant-reported issues.

### Metadata
Standardized documentation. [Spitschan2024BMCDigitHealth]

### Privacy aspects
Anonymization, PII handling.

### Locale consistency
Date/time formats, decimal markers.

### Recommended conventions for datetime
Best practices for timestamp handling.

## Maintaining Devices

### Cleaning
Hygiene and maintenance.

### Monitoring and correcting device drift
Detecting and recalibrating drift.

## Analysing Data

### Data cleaning and preprocessing
Non-wear, missing data, aggregation.

### Exploration and exploratory visualization
Visual strategies for time series.

### Merging data streams
Syncing sleep, activity, and light data.

### Adding context to the time series
Chronotype, location data, etc.

### Metric selection
Duration vs. intensity metrics.

### Special properties of light and visual experience data
Zero inflation, dynamic range.

## Reporting Data

### Methods section

For transparency and to ensure that others can replicate and reproduce the measurement protocol and study, it is key to document 

### Discussion section
Study design, device rationale.

### Metadata documentation
Thorough sharing practices.

### Code sharing
Preprocessing and analysis scripts. [@Zauner2025JOpenSourceSoftw]

### Data sharing
Ethical and practical aspects.

### Materials sharing

To ensure the reproducibility of research studies, it is recommended to share the materials used throughout the study, including any instruction sheets given to the participant, survey questions used, as well as debriefing documents. For any digital materials, such as forms served on a survey platform (such as REDCap), it is recommended, that the materials are provided in a format ingestible/importable by the platform

### FAIR data

The FAIR principles state that data should be **f**indable, **a**ccessible, **i**nteroperable and **r**eusable, to make them easier to share and reusable. Several of the points raised in this Researcher Guide are driven to ensure that visual experience and optical radiation data are FAIR, including standard file formats and documentation. Importantly, FAIR data guarantees that the collected data are used sustainably, and available well beyond the specific published research articles.

Data can be published as part of the supplementary material of journals. An alternative option is to add them as data packages to specific repositories, such as [Zenodo](https://zenodo.org/) or [FigShare](https://figshare.org/). 
