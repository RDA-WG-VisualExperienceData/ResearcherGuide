{
  "hash": "3401a6f882f1b224e3cdd51c8bb32b9d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"RDA Researcher Guide\"\nauthor: The Optical Radiation Exposure and Visual Experience Data Working Group\nbibliography: references.bib\nformat:\n  html:\n    toc: true\n    toc-location: left\n    toc-depth: 3\n    toc-expand: 2\n    mermaid:\n      config: mermaid-config.yaml\n    css: styles.css\n    execute:\n      echo: false\n      warning: false\n      message: false\n      error: false\nlightbox: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\nThis site will shortly host the Research Data Alliance (RDA) Research Guide. The Research Guide is authored by the [Optical Radiation Exposure and Visual Experience Data Working Group](https://www.rd-alliance.org/groups/optical-radiation-exposure-and-visual-experience-data-wg/activity/). The site is built using [Quarto](https://quarto.org/docs/websites), a scientific and technical publishing system.\n\nDRAFT – NOT FOR DISTRIBUTION\n\n# Introduction\n\nExposure to the optical environment, sometimes called visual experience, fundamentally affects human physiology and behaviour at multiple time scales. Two examples of such effects that have received significant attention come from different research domains, but can be understood through a common retinally-referenced framework. The first concerns the 'non-visual' effect of light on human circadian and neuroendocrine physiology: The light-dark cycle synchronises the biological clock, and exposure to light at night suppresses melatonin production [@Brown2022PLoSBiol; @Blume2019Somnologie]. The second concerns the potential effect of light exposure and visual experience on ocular development and specific myopia, in which time spent outdoors, and its associated visual experience, have been linked with ocular health outcomes [@DahlmannNoor2025GraefesArchClinExpOphthal].\n\n![Example light exposure](images/light_exposure.png)\n\nIn typical laboratory studies, light exposure can be fixed and held constant, or modulated parametrically. Such artificial exposures are very much unlike the real-world exposures to the optical environment that people received through the day. As people move in and between spaces (indoors and outdoors) and move their trunks, heads and eyes, the exposure to the optical environment varies significantly [@Webler2019CurrOpinBehavSci], and is modulated by behaviour [@Biller2024CommunPsychol]. As a consequence, understanding real-world exposure to link to real-world impacts requires real-world measurements, faciliated by wearable devices.\n\nStarting in the 1980s [@Okudaira1983AmJPhysiol], technology to measure exposure to the optical environment has been developed and matured, with miniaturized illuminance sensors now (2025) being very common in consumer smartwatches. In research, several device and device types are available, which differ in their functionality, ranging from small pin-like devices measuring light exposure [@Mohamed2021OptExpress] to head-mounted multi-modal measurement devices capturing almost all relevant aspects of visual experience [@Gibaldi2024TranslVisSciTechnol]. To make informed decisions about the properties of specific devices requires a careful ascertainment of their properties, and the specific trade-offs they entail.\n\n# Scope\n\nThe scope of this Researcher Guide is to provide a guide to using wearable devices measuring the optical environment. It is a living document and will be updated and versioned.\n\n# Workflow\n\nWe consider the following workflow:\n\n\n\n\n```{mermaid}\nflowchart TD\n    A[Selecting devices] --> B[Designing the study]\n    B --> C[Collecting data]\n    C --> D[Storing/documenting data]\n    D --> E[Analysing data]\n    E --> F[Reporting data]\n\n    A --> G[Validating devices]\n    G --> A\n\n    C --> H[Maintaining devices]\n    H --> C\n\n    style A fill:#f9d4d4,stroke:#000\n    style B fill:#f9d4d4,stroke:#000\n    style G fill:#f9d4d4,stroke:#000\n\n    style C fill:#f9dba9,stroke:#000\n    style H fill:#f9dba9,stroke:#000\n    style D fill:#f9dba9,stroke:#000\n\n    style E fill:#b7e4f9,stroke:#000\n    style F fill:#b7e4f9,stroke:#000\n\n    click A \"license.html\" _self\n    click B \"license.html\" _self\n    click C \"license.html\" _self\n    click D \"license.html\" _self\n    click E \"license.html\" _self\n    click F \"license.html\" _self\n    click G \"license.html\" _self\n    click H \"license.html\" _self\n```\n\n\n\n\n# Researcher Guide\n\n## Selecting devices\n\nThe first step in any project examining visual experience and light exposure is the choice of a device. This involves understanding the properties of different wearable devices, and several trade-offs. A recent survey found >50 wearable devices differing in form and function [@vanDuijnhoven2025BuildEnviron; with previous overviews in @Honekopp2023ClinOphthalmol; @Danilenko2022AppliedSci], indicating the need to make informed choices.\n\n### Measurement capabilities and sensor characteristics\nSpectral/photometric/α-opic metrics, sampling rate, uncertainty, cosine response, range, etc. [@Spitschan2022DigitHealth]\n\n\n#### Spectral sensitivity functions\n\nSpectral sensitivity [@CIE2018CIES026; @Lucas2014TrendsNeurosci]\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Directional properties\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Advanced and additional modalities\nSpatial resolution, movement tracking, UV/IR detection.\n\n### Manufacturer calibration\n\nDevices designed to measure light exposure and other aspects of the optical environment should come with information from the manufacturer on the calibration procedures used to ensure high-quality measurements. Sometimes, information for one exemplary device is included in a spec sheet or datasheet. It is worth consulting with the manufacturer on any calibrations they perform and specifically clarifying whether device-level information is available.\n\nThe manufacturer may also recommend recalibrations of the devices at regular intervals. It is worth understanding the rationale for any such recalibrations (in particular if they come at a cost), as well as any recalibrations that researchers themselves can do.\n\n### Size, form, and design\n\nThe size, form and design of a wearable light logger are particularly important for the specific contexts in which it will be used. Devices that are too heavy, bulky or impractically shaped will likely not be of particular use in field studies on light exposure. The most common form factors are devices that are **wrist-worn**, **lanyard-worn**, attached with a **clip**, or attached to **spectacle frames**.\n\n![Form factors and wearing locations](images/wearing_locations.png)\n\nDifferent form factors are susceptible to different types of occlusions, so beyond participant comfort, a device's dimensions and intended use case are also directly linked to data reliability. As of 2025, no specific device can be used all the time in all contexts and provide reliable information.\n\nCommon problems include:\n\n+ Wrist-worn devices are susceptible to being occluded by sleeves, particularly in settings or cold weather seasons.\n\n+ Lanyard-worn and clip-worn devices are susceptible to being occluded by jackets or other outer garments.\n\n+ Devices attached to spectacle frames are impractical for long-term use in the real world.\n\nPrevious studies [@Okudaira1983AmJPhysiol; @Jardim2011ChronobiolInt; @Aarts2017BuildEnviron; @Bhandari2021Sensors; @Wen2023BMJOpenOphthal; @Mohammadian2024IEEEInternetThingsJ] have shown that while wrist-worn measurements are correlated with chest or head measurements, they are not related by a simple relationship. This follows from the fact that the wrist and eyes point in different directions in different planes.\n\n### Battery capacity\nBattery life, charging cycles, power management.\n\n### Data storage\nStorage capacity, retention, and privacy.\n\n### Raw data format and ease of use\nExport formats, transfer speed, and syntactic structure.\n\n### Wear/non-wear and occlusion detection\n\nSome devices may be able to detect whether they are being worn, either online, or after analysis using the manufacturer-provided software. For wrist-worn devices, this could be implemented through a capacitance sensor, or temperature sensor, or in conjunction with data from the IMU. Additionally, devices might be able to detect it is occluded.\n\nWhen wear detection is not available from the device-inherent capabilities, it is recommended that researchers investigate concise methods for estimating wear/non-wear state, e.g. through additional questionnaires or using a data-driven approach.\n\n### Interaction with the device\n\nSome devices contain event buttons, which, when pressed, insert time-stamped information into the data log. This functionality can be very useful for determining wear/non-wear state and specific events taking place for the participant. It is worth noting that as they are a user interaction, participants are not guaranteed to do it consistently.\n\n### Documentation\n\nThe quality of manufacturer documentation can vary significantly, and it is important to consult the manufacturer on its completeness. This includes, at a minimum:\n\n* **Sensor capabilities and calibration**\n  + Full description of sensor capabilities, including calibration information  \n  + Traceability of calibration (e.g., to national standards)  \n  + Documentation of validation procedures (e.g., lab vs. field performance)  \n  + Instructions for user-performed recalibration and required tools  \n  + Expected lifespan and stability of sensor performance over time (e.g., sensor drift)  \n\n+ **Environmental and operational conditions**\n  + Environmental operating conditions (e.g., temperature, humidity, altitude)  \n  + Known hardware/software limitations (e.g., maximum sampling rate, data loss risks)  \n  + Information on error states or error modes that may be encountered during data collection  \n\n+ **Device behaviour and data processing**\n  + Description of any onboard data processing, compression, or classification algorithms  \n  + Details on how timestamps are generated and synchronized (e.g., internal clock behavior, drift)  \n  + Firmware versioning and changelog history, especially for devices under active development  \n\n+ **Data structure and output**\n  + Full description of all data available from the device  \n  + Clear explanation of file formats (CSV, JSON, binary, proprietary, etc.)  \n\n+ **Usage and deployment guidance**\n  + Recommended positioning and usage instructions to ensure data validity  \n\n+ **Regulatory and support information**\n  + Any relevant compliance certifications (e.g., [CE](https://europa.eu/youreurope/business/product-requirements/labels-markings/ce-marking/index_en.htm), [FCC](https://www.fcc.gov/), [ISO](https://www.iso.org/home.html))  \n  + Contact information for technical support \n\n### Software ecosystem\nFeatures for annotation, tagging, and version control. [@Zauner2025JOpenSourceSoftw]\n\n## Validating devices\n\nOnce devices have been acquired, a key step prior to deployment in a scientific study is their validation. \n\n### Standardized validation procedures\nGeneral principles and methodology.\n\n### Cross-comparison with reference measurements\nUsing standard light sources.\n\n### Inter-device variability assessment\n\nA simple and cheap method to characterise variability between devices is to place them under an overcast sky next to each other [@Markvart2015Leukos].\n\n### Intra-device reliability assessment\nSame-device repeatability.\n\n### Ease of calibration\nIndividual recalibration support.\n\n## Designing the protocol\n\nOnce devices are in hand, a key consideration is the design of a protocol.\n\n### Clarity on the research question and pre-registration\n\nThe research question, hypotheses, procedures, and methods need to be aligned in a tight way. In measuring visual experience and light exposure, this alignment becomes particularly important due to the changing and context-dependent nature of light. Measuring a single day of light exposure to draw conclusions about seasonal effects is methodologically flawed, neglecting intra- and inter-day fluctuations in weather, behaviour and exposures. For more robust measurements, typically, longer measurements are needed and include data from weekdays and weekends. Additionally, different work schedules [@Daugaard2019AnnWorkExpoHealth; @Price2021AnnWorkExpoHealth] and seasons at specific latitudes [@Cole1995JBiolRhythms; @Graw2000JAffectDisord; @Thorne2009ChronobiolInt; @Ulaganathan2018ActaOphthalmol; @Dunster2022JPinealRes] can lead to significant differences in exposure. At the same time, coverage needs to be balanced with participant burden.\n\nIt is important to clearly formulate the research question, hypotheses, procedures, and methods before the data collection. An additional step is to write a pre-registration detailing the protocol and analysis plans.\n\n### Participant burden vs. fidelity\nBalancing precision with practicality.\n\n### Measurement capabilities matched to use case\n\nSimilar to how the research question, hypotheses, procedures, and methods need to be tightly aligned, the measurement capabilities of the wearable devices needs to be matched to the measurement context (indoors, outdoors). For example, a wearable devices might not be suited to measure light exposure below 10 lx. If the goal is to measure dynamics in nocturnal light exposure, the device would not produce robust information. Similarly, distance sensors operate differently in different conditions (depending on the sensor technology).\n\n### Measurement length and time intervals\nSampling strategy and battery considerations.\n\n### Inclusion of other data\nSleep, activity, and context. [@Guidolin2045BMCPublicHealth]\n\n### Participant reactivity and inadvertant behavioral modification\n\nDifferent form factors and associated wearing locations could be susceptible to different ways that participants behave, a phenomenon similar to reactivity, in measurement leads to changes in the people being measured [@French2010BrJHealthPsychol]. For example, wearing a device attached to spectacle frames may not be very suitable for public environments, workplace, or specific recreational contexts. Consequently, participants may change their behaviour in response to the visibility, intrusiveness, or comfort of the device, leading to reactivity—i.e., modifications in naturalistic behaviour due to awareness of being monitored.\n\nSuch behavioural adaptations can include reduced social interaction, altered outdoor time, or avoidance of certain activities (e.g., sports, commuting via bicycle). These changes may introduce systematic biases in the collected data, particularly if the device form factor is not well tolerated across all settings or participants.\n\nTo probe for such biases, it may be advisable to include a questionnaire or single open-ended question after data collection asking whether they perceived any changes in their behaviour due to wearing the devices.\n\n## Collecting data\n\nWith the protocol final and registered, data collection commences. There are several aspects that need to be considered.\n\n### Briefing of participants\n\nParticipants should receive clear instructions on\n\n+ wearing the device, including suitable contexts and situations (related to the durability and IP rating of the device)\n+ handling the device when they take it off, including logging it\n+ charging the device regularly (if necessary)\n\nTo ensure that participants understand the instructions clearly, it is recommended that a short comprehension check be included after the briefing. This can be done by asking participants to repeat key instructions in their own words or having participants demonstrate how to wear, remove, and charge the device correctly. A printed or digital instruction sheet can be supplied for reference.\n\nAdditionally, if there are any known problems with the devices, these should be communicated to the participants.\n\n### Recurrent compliance checks\n\nThroughout a measurement protocol, it could be helpful to implement regular checks to remind participants of key steps involved in the measurement, including charging. In case there is online access to the data, such as through clouds, it is possible to monitor light exposure instantaneously and remotely. This can bring several benefits, including the possibility of corrective action should a participant not comply to the study procedures.\n\nCompliance related to usability can be probed and measured using specific questionnaires [@Balajadia2023DigitBiomarkers; @Stefani2024ClockSleep].\n\n### Device settings\n\nA time-stamped and versioned standard operating procedure (SOP) document can help ensure the reproducibility of device settings when there are multiple operators setting up devices for studies. A key component is to ensure the same parameters, but also other configuration flags being consistently used for logging.\n\nLogging configuration, time sync, DST handling.\n\n## Storing and documenting data\n\nAs data is coming in, it is important to take care that the data are stored safely.\n\n### Documentation principles\n\nA minimum approach includes the use of a README file that describes the data collected [@Zielinski2023ClocksSleep].\n\n### Consistent file format\nNon-proprietary standard formats.\n\n### Auxiliary data\nSurveys, companion apps.\n\n### Standard directory structure\nFile organization.\n\n### Documentation of anomalies\nParticipant-reported issues.\n\n### Metadata\n\nMetadata is data about data. Standardized documentation. [@Spitschan2024BMCDigitHealth]\n\n### Privacy aspects\n\nFor any biomedical data collection, privacy principles relevant to the local jurisdictions need to be upheld (e.g. [HIPAA](https://www.hhs.gov/hipaa/for-professionals/privacy/laws-regulations/index.html), [GDPR](https://eur-lex.europa.eu/eli/reg/2016/679/oj/eng), ...). Careful consideration needs to be placed on which aspects of data contain personally identifiable information. It is not clear whether visual experience and light exposure, or time courses thereof, constitute personally identifiable information. More research needs to be done to understand the identifiability of people from their visual experience data.\n\n### Locale consistency\n\n[Locale](https://en.wikipedia.org/wiki/Locale_(computer_software)) in computer software is a set of parameters that define how information is displayed and stored. The parameters cover language, region, and individual preferences. Locales are important because software, especially gui-heavy software like Microsoft Excel, interpret data based on a user's locale: what is the decimal marker, how are columns separated in text files, what are datetime conventions, etc. More problematic, however, is that some software, even research-focused companion software to wearable devices, also save files with the settings defined by a users locale. This leads to a myriad of dialects in theoretically well defined text-based files, like CSV (comma separated values), thus making the FAIR exchange of data between researchers more burdensome. The most common CSV deviation, typical, e.g., for some European countries, uses a semicolon ';' as a column divider instead of the eponymous comma ','. Very likely, this is because the comma in this dialect is used as a decimal mark instead of the full stop '.'.\n\nWe do not necessarily recommend for a researcher to change their locale settings on research machines (although that would help). It is, however, important that researchers are aware of the nature and influence of the locale, and we recommend the following:\n\n- Avoid wearable devices that store data based on a user's locale without explicit prompt\n\n- Make certain that whatever import routine is used for wearable data matches the raw files, and that there are no differences between the files. If this cannot be avoided, import files separately depending on the locale.\n\n- Always check the correct interpretation of text-based data in the software of choice, especially regarding decimals, column separation, and datetimes\n\n- The analysis software LightLogR provides import routines that are based on typical settings for wearable devices. This means that by default, LightLogR users do not have to take care about locale settings, exept when device data is stored with deviant settings. [LightLogR's documentation page for import](https://tscnlab.github.io/LightLogR/reference/import_Dataset.html) will mention known deviations in file formats, and new ones can be reported.\n\n- Never overwrite a text-based file with software that changes a files' locale conventions without notice. Microsoft Excel is a common offender, as it seems to interpret foreign locales correctly, but switches to the user's locale upon saving (if the user does not actively choose a different format). At best, this potentially fragments a study's data base, if some files are opened and resaved (e.g., when removing a header or correct some spelling), while others are not. At worst, it will misinterpret a text-string, e.g. interpreting a value of '2.04' as '2 April', which will be stored in the text file as a date, e.g. as '02-04-2025'. This type of data corruption can be easily missed at first, only to be noticed during analysis, sometimes with no mode of recovery.\n\n### Recommended conventions for datetime\n\nTimestamps for wearable data need to contain datetime information in a consistent, unambiguous, and machine-readable format. Because there are many time zones around the world, datetimes are a complex topic and need to be handled with care. A time zone should not be confused with the offset from Coordinated Universal Time (UTC), although for any given moment, a time zone can be related to a specific offset. Time zones also include information about whether or not there is daylight savings, and if the offset changes (e.g., due to policy). This means that local time + time zone contains more information than local time + offset. Date, time, and datetimes are standardized in [ISO 8601](https://www.iso.org/iso-8601-date-and-time-format.html), and it is recommended that datetimes follow its conventions. A comprehensive description of the structure can be found [here](https://datatracker.ietf.org/doc/html/rfc3339#section-5.6). \n\nAt the time of this writing (2025), most devices do not store the offset to UTC as part of the timestamp, which regularly results in ambiguity following switches to and from daylight savings. This ambiguity can be avoided if:\n\n- datetimes follow the conventions in iso 8601\n\n- datetimes are stored in UTC format with a known time zone, taken from the [Olson/IANA](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) databases.\n\n## Maintaining devices\n\nThroughout data collection, devices need to be maintained.\n\n### Cleaning\n\nDevices and attachment pieces such as lanyard should be cleaned between different participants. The manufacturer should provide instructions for this, to ensure that any cleaning instructions are consistent and compatible with the specific materials used.\n\n### Monitoring and correcting device drift\nDetecting and recalibrating drift.\n\n## Analysing data\n\nFollowing data collection, data are analysed.\n\n### Data cleaning and preprocessing\n\nDue to non-wear at times of day at which specific activities occur (e.g., showering, contact sports, swimming, ...), light exposure data may be missing systematically. Data may also be missing if the light exposure falls short of or exceeds the sensor range.\n\nThe following sanity checks are recommended:\n\n+ Visualisation of raw time series for the available sensors\n+ Visualisation of histogram to identify distributions of data and outliers\n\nNon-wear, missing data, aggregation.\n\n### Exploration and exploratory visualization\nVisual strategies for time series.\n\n### Merging data streams\nSyncing sleep, activity, and light data.\n\n### Adding context to the time series\nChronotype, location data, etc.\n\n### Metric selection\n\nTime-series of light exposure and visual experience data can be analysed using a series of metrics [@Hartmeyer2023LightResTechnol; @Zauner2025JOpenSourceSoftw]. Importantly, there are no standard metrics for the analysis of light exposure data that have been robustly and reliably linked to outcome metrics. Given the lack of standard metrics, researchers must pay particular attention to analytic flexibility leading to inflated false positive rates in statistical analysis.\n\nDuration vs. intensity metrics.\n\n### Special properties of light and visual experience data\n\nLight exposure data spans a wide dynamic range, mirroring the differences in possible environmental exposures from the scotopic to the photopic range of light levels. This means that data are usually considered in a log~10~-transformed fashion.\n\nAn additional statistical property of 24-hour light exposure data is that it is heavily zero-inflated, due to the lack of light at night, or light below the measurement threshold of the device. \n \n### Implementation\n\nIt is recommended that analysis of visual experience data is implemented using programmatic tools, such as [R](https://www.r-project.org/), [Python](https://www.python.org/) or [MATLAB](https://de.mathworks.com/products/matlab.html). [LightLogR](https://tscnlab.github.io/LightLogR/) [@Zauner2025JOpenSourceSoftw] offers a powerful [open-source tool](https://github.com/tscnlab/LightLogR/) available on [CRAN](https://cloud.r-project.org/web/packages/LightLogR/index.html) for the analysis of light exposure and visual experience data.\n\n## Reporting data\n\nUpon conclusion of the data collection, the next step is to report the data and associated results.\n\n### Methods section\n\nFor transparency and to ensure that others can replicate and reproduce the measurement protocol and study, it is key to document various aspects related to the measurement of visual experience and light exposure. At a minimum, it is recommended to include text on the following points:\n\n* **Device-related properties**\n\t+ Manufacturer, brand and make of wearable device used\n\t+ Wearing location\n\t+ Sampling interval\n\t+ Measured quantities\n\t+ Calibration information on directional sensitivity, spectral sensitive, linearity and range properties\n\t\n* **Protocol-related properties**\n\t+ Location and season of data collection\n\t+ Time zone and changes (e.g., daylight saving time)\n\t+ Wearing location\n\t+ Wearing duration\n\t+ Instructions given to the participant for wear context and non-wear behaviour\n\t+ Criteria for inclusion/exclusion based on wear time and compliance\n\t+ Use of prompts/reminders to ensure compliance\n\n* **Analysis-related properties**\n\t+ Preprocessing of data, including outlier rejection, binning and smoothing\n\t+ Handling of partial or missing data\n\t+ Analysis routines and functions used\n\t+ Software and version used for analysis and open-source availability\n\nFuture work may formalise these recommendations in the form of a consensus checklist.\n\n### Discussion section\n\nIt is recommended that the Discussion section discloses various limitations arising from the choice of devices or protocols, such as the inability to measure visual experience in the near-corneal plane using wrist-worn devices. Additionally, the rationale for device selection, protocol design and analysis choices should be explained.\n\n### Metadata documentation\nThorough sharing practices.\n\n### Sharing code\n\nThe code used to analyse the data is not just a byproduct of the research process, but a result by itself. There are several reasons to make code available under an open source license:\n\n+ The work underlying the scientific results is shared sustainably for re-use and independent checking\n+ The researcher community can benefit from the availability of existing and citable code\n\nCode can be shared as static files attached to the supplementary material of a published article, or on a repository, such as [GitHub](https://github.com/) or [Bitbucket](https://bitbucket.org/). For GitHub, [Zenodo](https://zenodo.org/) offers an integration module such that when creating a release on GitHub, Zenodo creates a DOI, making the code citable.\n\nImportantly, when sharing code, it is necessary to select a license under which the code is available. Common licenses include the [MIT License](https://opensource.org/license/mit), which is permissive with respect to commercial use, and the [GPL License](https://opensource.org/license/gpl-3-0), which is more restricted. [Choose a License](https://choosealicense.com/) can help making an informed decisions about software licenses.\n\nCode reproducibility can be ensured through independent validation through [CODECHECK](https://codecheck.org/) [@Nust2021F1000Research].\n\n### Sharing materials\n\nTo ensure the reproducibility of research studies, it is recommended to share the materials used throughout the study, including any instruction sheets given to the participant, survey questions used, as well as debriefing documents. For any digital materials, such as forms served on a survey platform (such as [REDCap](https://project-redcap.org/)), it is recommended, that the materials are provided in a format ingestible/importable by the platform\n\n### Sharing data\nEthical and practical aspects.\n\nIt is recommended that when researchers submit their ethics approval request, they already include the provision of sharing data in anonymized form. It can be very difficult to impractical to share data after the fact or seek re-approval from the participants.\n\n### FAIR data\n\nThe [FAIR principles](https://www.go-fair.org/fair-principles/) state that data should be **f**indable, **a**ccessible, **i**nteroperable and **r**eusable, to make them easier to share [@Wilkinson2016SciData]. Several points raised in this Researcher Guide are driven to ensure that visual experience and optical radiation data are FAIR, including standard file formats and documentation. Importantly, FAIR data guarantees that the collected data are used sustainably, and available well beyond the specific published research articles.\n\nData can be published as part of the supplementary material of journals. An alternative option is to add them as data packages to specific repositories, such as [Zenodo](https://zenodo.org/) or [FigShare](https://figshare.org/). \n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}